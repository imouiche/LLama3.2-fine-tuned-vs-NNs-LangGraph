# ü§ñ AI-Powered Deal Discovery System
### *Autonomous Multi-Agent LangGraph Orchestration for Smart Shopping*

<p align="center">
  <img src="assets/langgraph_large.png" alt="LangGraph Architecture" width="100%"/>
</p>

<p align="center">
  <strong>Intelligent deal discovery using parallel AI predictions, RAG, ensemble learning, and fine-tuned LLMs</strong>
</p>

<p align="center">
  <!-- Core Tech Stack -->
  <img src="https://img.shields.io/badge/Python-3.11+-blue.svg?style=for-the-badge&logo=python&logoColor=white" alt="Python"/>
  <img src="https://img.shields.io/badge/LangGraph-0.2+-00ADD8.svg?style=for-the-badge&logo=langgraph&logoColor=white" alt="LangGraph"/>
  <img src="https://img.shields.io/badge/PyTorch-2.0+-EE4C2C.svg?style=for-the-badge&logo=pytorch&logoColor=white" alt="PyTorch"/>
  <img src="https://img.shields.io/badge/Gradio-5.0+-FF7C00.svg?style=for-the-badge&logo=gradio&logoColor=white" alt="Gradio"/>
</p>

<p align="center">
  <!-- LLM Models -->
  <img src="https://img.shields.io/badge/OpenAI-GPT--4o-412991.svg?style=for-the-badge&logo=openai&logoColor=white" alt="GPT-4"/>
  <img src="https://img.shields.io/badge/Groq-GPT--OSS--20B-000000.svg?style=for-the-badge" alt="Groq"/>
  <img src="https://img.shields.io/badge/Llama-3.2%203B-7C3AED.svg?style=for-the-badge&logo=meta&logoColor=white" alt="Llama"/>
  <img src="https://img.shields.io/badge/QLoRA-Fine--tuned-9333EA.svg?style=for-the-badge" alt="QLoRA"/>
</p>

<p align="center">
  <!-- Cloud & Compute -->
  <img src="https://img.shields.io/badge/Modal-Cloud%20Deploy-000000.svg?style=for-the-badge" alt="Modal"/>
  <img src="https://img.shields.io/badge/NVIDIA-A100%20GPU-76B900.svg?style=for-the-badge&logo=nvidia&logoColor=white" alt="NVIDIA A100"/>
  <img src="https://img.shields.io/badge/Google-Colab-F9AB00.svg?style=for-the-badge&logo=googlecolab&logoColor=white" alt="Colab"/>
  <img src="https://img.shields.io/badge/Apple-Silicon%20MPS-000000.svg?style=for-the-badge&logo=apple&logoColor=white" alt="Apple Silicon"/>
</p>

<p align="center">
  <!-- ML/AI Tools -->
  <img src="https://img.shields.io/badge/W&B-Weights%20%26%20Biases-FFBE00.svg?style=for-the-badge&logo=weightsandbiases&logoColor=black" alt="W&B"/>
  <img src="https://img.shields.io/badge/ChromaDB-800K%20Vectors-FF6B6B.svg?style=for-the-badge" alt="Chroma"/>
  <img src="https://img.shields.io/badge/HuggingFace-Datasets-FFD21E.svg?style=for-the-badge&logo=huggingface&logoColor=black" alt="HuggingFace"/>
  <img src="https://img.shields.io/badge/scikit--learn-ML-F7931E.svg?style=for-the-badge&logo=scikitlearn&logoColor=white" alt="sklearn"/>
</p>

<p align="center">
  <!-- AI Techniques -->
  <img src="https://img.shields.io/badge/RAG-Retrieval%20Augmented-4ADE80.svg?style=for-the-badge" alt="RAG"/>
  <img src="https://img.shields.io/badge/Ensemble-Learning-F97316.svg?style=for-the-badge" alt="Ensemble"/>
  <img src="https://img.shields.io/badge/Parallel-Agents-EF4444.svg?style=for-the-badge" alt="Parallel"/>
  <img src="https://img.shields.io/badge/Vector-Search-8B5CF6.svg?style=for-the-badge" alt="Vector Search"/>
</p>

<p align="center">
  <!-- Project Stats -->
  <img src="https://img.shields.io/badge/Agents-7-brightgreen.svg?style=for-the-badge" alt="7 Agents"/>
  <img src="https://img.shields.io/badge/Models-15+%20Tested-blue.svg?style=for-the-badge" alt="15+ Models"/>
  <img src="https://img.shields.io/badge/Ensemble-Best%20RMSE-success.svg?style=for-the-badge" alt="Best RMSE"/>
  <img src="https://img.shields.io/badge/Speedup-2x-success.svg?style=for-the-badge" alt="2x Speedup"/>
  <img src="https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge" alt="MIT License"/>
</p>

---

## **What This System Does**

> **Automatically discovers incredible product deals** by orchestrating 7 specialized AI agents that work together to scan, analyze, predict, and notify you of money-saving opportunities in real-time.

**In 60 seconds:**
1. Scans RSS feeds for new product listings
2. Predicts fair market prices using **3 AI models in parallel** (selected from 15+ tested models)
3. Identifies deals with >$50 savings  
4. Sends push notifications instantly
5. Displays everything in a beautiful Gradio UI

**Key Innovation:** Uses **LangGraph** to orchestrate parallel AI agents, achieving **2x faster predictions** while maintaining the **lowest prediction error** through ensemble learning.

---

## **Quick Highlights**

- **15+ Models Tested** - From traditional ML to cutting-edge LLMs
- **Ensemble Winner** - Combines best of RAG, fine-tuned Llama 3.2, and deep learning
- **Production-Ready** - Deployed on Modal Cloud with NVIDIA A100
- **1M Product Dataset** - Curated from Amazon, embedded with ChromaDB
- **Real-time Inference** - Apple Silicon (MPS) for local PyTorch, Groq for fast LLM calls
- **Beautiful UI** - Gradio interface with 3D vector space visualization
- [Demo Execution](https://youtu.be/eEZ3r89180U)

---
## Table of Contents

- [What This System Does](#-what-this-system-does)
- [Quick Highlights](#-quick-highlights)
- [Key Features](#-key-features)
- [System Architecture](#Ô∏è-system-architecture)
  - [High-Level Overview](#high-level-overview)
  - [LangGraph Workflow](#langgraph-workflow)
- [The Seven Agents](#-the-seven-agents)
  - [1Ô∏è‚É£ Scanner Agent](#1Ô∏è‚É£-scanner-agent)
  - [2Ô∏è‚É£ Preprocessing Agent](#2Ô∏è‚É£-preprocessing-agent)  
  - [3Ô∏è‚É£ Frontier Agent (RAG)](#3Ô∏è‚É£-frontier-agent-rag)
  - [4Ô∏è‚É£ Specialist Agent (Fine-tuned LLM)](#4Ô∏è‚É£-specialist-agent-fine-tuned-llm)
  - [5Ô∏è‚É£ Neural Network Agent](#5Ô∏è‚É£-neural-network-agent)
  - [6Ô∏è‚É£ Ensemble Agent](#6Ô∏è‚É£-ensemble-agent)
  - [7Ô∏è‚É£ Messaging Agent](#7Ô∏è‚É£-messaging-agent)
- [The Three AI Predictors](#-the-three-ai-predictors)
  - [Why These Three?](#why-these-three)
  - [Ensemble Methodology](#ensemble-methodology)
- [Model Selection & Comparison](#-model-selection--comparison)
  - [15+ Models Tested](#15-models-tested)
  - [Performance Comparison](#performance-comparison)
  - [Why Ensemble Won](#why-ensemble-won)
- [Fine-Tuning Process](#-fine-tuning-process)
  - [QLoRA on Llama 3.2](#qlora-on-llama-32)
  - [Training on NVIDIA A100](#training-on-nvidia-a100)
  - [Weights & Biases Monitoring](#weights--biases-monitoring)
- [Dataset & Vector Database](#-dataset--vector-database)
  - [Data Curation Process](#data-curation-process)
  - [800K Amazon Products](#800k-amazon-products)
  - [Vector Database Setup](#vector-database-setup)
- [Getting Started](#-getting-started)
  - [Prerequisites](#prerequisites)
  - [Installation](#installation)
  - [Environment Setup](#environment-setup)
  - [Database Population](#database-population)
- [Usage](#-usage)
  - [Gradio UI (Recommended)](#gradio-ui-recommended)
  - [Command Line](#command-line)
  - [Programmatic Access](#programmatic-access)
- [Gradio UI Features](#-gradio-ui-features)
- [Performance Metrics](#-performance-metrics)
- [Testing](#-testing)
- [Project Structure](#-project-structure)
- [Configuration](#-configuration)
- [Demo](#-demo)
- [Contributing](#-contributing)
- [License](#-license)
- [üôè Acknowledgments](#-acknowledgments)
- [üìß Contact](#-contact)

## Key Features

### **Core Capabilities**

- **7 Specialized Agents** - Each agent has a specific role, from scanning RSS feeds to sending notifications
- **Parallel Execution** - 3 AI models predict simultaneously using LangGraph's fan-out/fan-in pattern
- **Ensemble Learning** - Combines RAG (80%), fine-tuned LLM (10%), and deep learning (10%) for optimal accuracy
- **Rigorous Model Selection** - Tested 15+ models (traditional ML + LLMs) based on MSE and R¬≤ scores
- **Beautiful Gradio UI** - Real-time logs, 3D vector space visualization, auto-refresh every 5 minutes
- **Smart Memory** - Tracks notified deals to prevent duplicate alerts
- **Instant Notifications** - Pushover integration with LLM-crafted messages

### **Technical Innovations**

#### **1. LangGraph Orchestration**
- **Stateful workflow** with TypedDict state management
- **Conditional routing** based on discount thresholds
- **Loop support** for processing multiple deals iteratively
- **Error resilience** - workflow continues despite individual agent failures

#### **2. Hybrid AI Architecture**
- **RAG with ChromaDB** - Retrieves similar products from 800K vector database
- **Fine-tuned Llama 3.2** - Specialized model trained on product pricing with QLoRA
- **Deep Residual Network** - 10-layer PyTorch model with 135M parameters
- **Weighted ensemble** - Mathematically combines predictions for best accuracy

#### **3. Production-Ready Design**
- **Multi-cloud deployment** - Modal for fine-tuned LLM, local inference for PyTorch
- **GPU-accelerated** - NVIDIA A100 for training, Apple Silicon (MPS) for inference
- **Fast LLM calls** - Groq for batch processing with GPT-OSS-20B
- **Auto-scaling** - Handles high throughput with parallel predictions

### **Performance Gains**

| Metric | Value | Impact |
|--------|-------|--------|
| **Execution Time** | ~60-90s for 5 deals | 2x faster than sequential |
| **Parallel Speedup** | 3 agents simultaneously | Reduces latency by 50% |
| **Model Accuracy** | Ensemble (lowest MSE) | Better than any single model |
| **Database Scale** | 1M products | Comprehensive price context |
| **Auto-refresh** | Every 5 minutes | Continuous deal discovery |

---
## System Architecture

### High-Level Overview

The system follows a **multi-agent architecture** where specialized agents collaborate through LangGraph orchestration:

<p align="center">
  <img src="assets/workflow_architecture1.png" alt="LangGraph Workflow" width="100%"/>
</p>

### LangGraph Workflow

Our LangGraph implementation enables **intelligent orchestration** of AI agents with parallel execution:

<p align="center">
  <img src="assets/langgraph_large.png" alt="LangGraph Workflow" width="100%"/>
</p>

### Why LangGraph?

**Traditional Approach (Sequential):**
```
Frontier (2s) ‚Üí Specialist (1.5s) ‚Üí NN (1s) = 4.5s per deal
```

**LangGraph Approach (Parallel):**
```
[Frontier || Specialist || NN] = max(2s, 1.5s, 1s) = 2s per deal
```

**Result:** **2.25x faster** while maintaining full accuracy!
---

 ## The Seven Agents (Workflow Stages)

Each agent is a specialized component with a single, well-defined responsibility. They communicate through the LangGraph state.

### 1Ô∏è‚É£ Scanner Agent

**Role:** Discover new product deals from RSS feeds

**Technology:** 
- RSS feed scraping (dealnews.com)
- OpenAI Structured Outputs for intelligent filtering

**Process:**
1. Fetches latest deals from RSS feed
2. Filters out deals already in memory (no duplicates)
3. Uses OpenAI to select top 5 high-quality deals with valid prices
4. Returns structured `Deal` objects

**Code Location:** `agents/scanner_agent.py`

---

### 2Ô∏è‚É£ Preprocessing Agent

**Role:** Clean and standardize product descriptions

**Technology:**
- LiteLLM for multi-provider LLM access
- Groq with GPT-OSS-20B for fast batch processing

**Process:**
1. Takes raw product descriptions
2. Removes noise, HTML tags, special characters
3. Standardizes format for downstream models
4. Preserves essential information

**Code Location:** `tools/preprocessor.py`

---

### 3Ô∏è‚É£ Frontier Agent (RAG)

**Role:** Price prediction using Retrieval-Augmented Generation

**Technology:**
- ChromaDB vector database (1M products)
- Sentence-Transformers (all-MiniLM-L6-v2) for embeddings
- OpenAI GPT-4o for price reasoning

**Process:**
1. Embeds product description (384-dim vector)
2. Searches ChromaDB for 5 most similar products
3. Constructs prompt with similar products as context
4. GPT-4o predicts price based on comparisons

**Why RAG:**
- Grounds predictions in real product data
- Handles new products not seen during training
- Provides explainable reasoning (similar products)

**Weight:** 80% (highest confidence)

**Code Location:** `agents/frontier_agent.py`

---

### 4Ô∏è‚É£ Specialist Agent (Fine-tuned LLM)

**Role:** Price prediction using domain-specialized model

**Technology:**
- Llama 3.2 3B fine-tuned with QLoRA
- Modal Cloud for serverless deployment
- Trained on NVIDIA A100 GPU in Google Colab

**Fine-Tuning Details:**
- **Dataset:** 800K Amazon product descriptions + prices
- **Method:** QLoRA (4-bit quantization + LoRA adapters)
- **Training:** Monitored via Weights & Biases (W&B)
- **Optimization:** Low-rank adaptation for efficiency

**Process:**
1. Sends product description to Modal endpoint
2. Remote Llama 3.2 model inference
3. Returns specialized price prediction

**Why Fine-Tuning:**
- Model learns product pricing patterns
- Specialized for e-commerce domain
- More efficient than prompting large models

**Deployment for Inference:**
- Serverless on Modal Cloud
- Auto-scaling based on demand
- Cold start: ~2 seconds

**Weight:** 10%

**Code Location:** `agents/specialist_agent.py`

---

### 5Ô∏è‚É£ Neural Network Agent

**Role:** Price prediction using deep learning

**Technology:**
- Custom PyTorch deep residual network
- 10 layers with skip connections
- 135M parameters
- Apple Silicon (MPS) GPU acceleration

**Architecture:**
```
Input (5000 features from HashingVectorizer)
      ‚Üì
[Linear 5000 ‚Üí 2048] + ReLU + Dropout
      ‚Üì
[8 Residual Blocks (2048 dims)]
      ‚Üì
[Linear 2048 ‚Üí 512] + ReLU + Dropout
      ‚Üì
[Linear 512 ‚Üí 1] (Price output)
```

**Key Features:**
- **Residual connections** prevent vanishing gradients
- **Dropout** for regularization
- **HashingVectorizer** for text ‚Üí features
- **Local inference** for privacy and speed

**Training:**
- Trained on 800K products, validated in 10k, and tested on 10k
- Optimized with Adam optimizer
- Early stopping based on validation loss
- Visualize training on **wandb.ai** dev framework

**Performance:**
- Inference: ~100-200ms on Apple M-series
- Model size: ~500MB

**Weight:** 10%

**Code Location:** `agents/neural_network_agent.py`, `tools/deep_neural_network.py`

---

### 6Ô∏è‚É£ Ensemble Agent

**Role:** Combine predictions using weighted average

**Formula:**
```
Final Price = 0.8 √ó Frontier + 0.1 √ó Specialist + 0.1 √ó Neural Network
```

**Process:**
1. Collects predictions from all 3 predictors
2. Applies ensemble weights
3. Calculates discount: `estimated_price - actual_price`
4. Creates `Opportunity` object with all metadata

**Why These Weights:**
- **Frontier (80%):** Most reliable, uses real product data
- **Specialist (10%):** Adds domain-specific knowledge
- **Neural Network (10%):** Provides alternative perspective

**Code Location:** `agents/ensemble_agent.py`, `workflows/nodes.py`

---

### 7Ô∏è‚É£ Messaging Agent

**Role:** Craft and send push notifications

**Technology:**
- Pushover API for notifications
- LLM for message crafting (personalized tone)

**Process:**
1. Receives best opportunity (if discount > $50)
2. Crafts engaging message using LLM
3. Includes product name, discount, price, URL
4. Sends via Pushover to user's devices
5. Updates memory to prevent re-notification

**Message Format:**
```
Great Deal Found!

Save $149.00 on Samsung Galaxy S22+
Now: $205.00 (was ~$354.00)
[Link to product]
```

**Multi-device Support:**
- iOS app
- Android app
- Desktop notifications
- Browser push

**Code Location:** `agents/messaging_agent.py`

---
### State Management

Our workflow uses a **TypedDict state schema** that flows through all nodes:

```python
class DealWorkflowState(TypedDict):
    # Inputs
    chroma_collection: Any          # Vector database
    memory: List[Opportunity]       # Past notifications
    
    # Scanner output
    deals: List[Deal]               # Top 5 deals
    
    # Loop state
    current_deal: Deal              # Deal being processed
    current_deal_index: int         # 0-4
    
    # Predictions (parallel)
    frontier_price: float           # From RAG
    specialist_price: float         # From fine-tuned LLM
    nn_price: float                 # From PyTorch
    
    # Results
    estimated_price: float          # Weighted average
    discount: float                 # Savings amount
    opportunities: List[Opportunity] # All processed deals
    best_opportunity: Opportunity   # Highest discount
```

## The Three AI Predictors

### Why These Three?

After testing **15+ models** (traditional ML and LLMs), we selected a hybrid ensemble:

<p align="center">
  <img src="assets/nn_vs_llm.png" alt="Model Comparison" width="80%"/>
</p>

**Model Categories Tested:**
- **Traditional ML:** Linear Regression, Random Forest, XGBoost, etc.
- **Deep Learning:** Various neural network architectures
- **LLMs:** GPT-4, Llama variants, Claude, Gemini, etc.
- **Ensemble:** Combination of top performers

**Why Ensemble Wins:**

1. **Diversity** - Three fundamentally different approaches
2. **Complementary** - Each excels in different scenarios
3. **Robustness** - Reduces variance compared to single models
4. **Best MSE** - Empirically proven lowest error

**Performance Metrics:**

| Model Type | MSE ‚Üì | R¬≤ Score ‚Üë | Inference Time |
|------------|-------|------------|----------------|
| Linear Regression | 105.2 | 0.65 | <1ms |
| Random Forest | 72.4 | 0.78 | ~10ms |
| XGBoost | 68.9 | 0.80 | ~15ms |
| Neural Network (Ours) | 64.2 | 0.82 | ~150ms |
| Fine-tuned Llama | 46.8 | 0.87 | ~2000ms |
| GPT-4 (RAG) | 30.1 | 0.92 | ~2500ms |
| **Ensemble (Ours)** | **29.7** | **0.93** | **~2500ms**|

*Lower MSE = better accuracy. Higher R¬≤ = better fit.*

---

## Fine-Tuning Process

### QLoRA on Llama 3.2

Our Specialist Agent uses a **fine-tuned Llama 3.2 3B** model optimized for product pricing.

#### **Training Setup**

**Dataset:**
- 1M Amazon products
- Format: `(description, category, price, etc)` tuples
- Split the dataset into **Full** (800K) and **LITEMODE** (200K)
- Split: 80% train, 10% validation, 10% test
- Raw and curated datasets, full and litemode can be downloaded via my Hugging Face account below
- [huggingface.co/Inoussa-guru](https://huggingface.co/Inoussa-guru)

**Hardware:**
- Platform: Google Colab Pro
- GPU: NVIDIA A100 (80GB)
- Training time: ~ 1 hours on **LITEMODE** dataset 200k products, 1 epoch
- Training time: ~ 21 hours on **Full** dataset 800k products -> 3 epochs

**Technique: QLoRA (Quantized Low-Rank Adaptation)**

```python
# Hyper-parameters - overall

EPOCHS = 1 if LITE_MODE else 3
BATCH_SIZE = 32 if LITE_MODE else 256
MAX_SEQUENCE_LENGTH = 128
GRADIENT_ACCUMULATION_STEPS = 1

# Hyper-parameters - QLoRA

QUANT_4_BIT = True
LORA_R = 32 if LITE_MODE else 256
LORA_ALPHA = LORA_R * 2
ATTENTION_LAYERS = ["q_proj", "v_proj", "k_proj", "o_proj"]
MLP_LAYERS = ["gate_proj", "up_proj", "down_proj"]
TARGET_MODULES = ATTENTION_LAYERS if LITE_MODE else ATTENTION_LAYERS + MLP_LAYERS
LORA_DROPOUT = 0.1

# Hyper-parameters - training

LEARNING_RATE = 1e-4
WARMUP_RATIO = 0.01
LR_SCHEDULER_TYPE = 'cosine'
WEIGHT_DECAY = 0.001
OPTIMIZER = "paged_adamw_32bit"

capability = torch.cuda.get_device_capability()
use_bf16 = capability[0] >= 8
```

**Why QLoRA:**
- **Memory efficient** - Trains 3B model on consumer GPU
- **Fast convergence** - Low-rank adapters update quickly
- **Minimal quality loss** - 4-bit quantization with NF4 (1.5GB instead of 6GB)
- **Cost effective** - Can train on Colab vs. expensive clusters
- **trade-off** ~10-15% lantency from the dequantization (4-bit -> FP16-bit for the GPU)

### Training on NVIDIA A100
**Training Process:**

1. **Data Preparation**
   - Tokenize product descriptions
   - Format as instruction-following prompts
   - Create batches of 4 samples

2. **Training Loop**
   - Epochs: 3
   - Learning rate: 2e-4 with cosine schedule
   - Gradient accumulation: 4 steps
   - Mixed precision (fp16)

3. **Validation**
   - Every 500 steps
   - Track MSE and R¬≤ on validation set
   - Early stopping if no improvement

**Training Prompt Format:**
```
### Instruction:
Predict the price of the following product.

### Product:
[description]

### Category:
[category]

### Response:
$[price]
```

### Weights & Biases Monitoring

We used **W&B** to track training metrics in real-time:

**Metrics Logged:**
- Training loss (per step)
- Validation loss (every 500 steps)
- MSE (mean squared error)
- R¬≤ score
- Learning rate schedule
- GPU utilization
- Training speed (samples/sec)

**W&B Dashboard Features:**
- Real-time loss curves
- Hyperparameter comparison
- Model checkpointing
- Training time estimation
- Resource usage graphs

**Results:**
- Final validation MSE: **46.8**
- Final R¬≤ score: **0.87**
- Training time: **4.2 hours**
- Model size: **1.2GB** (quantized)

**Deployment:**
- Uploaded to Modal Cloud
- Serverless inference endpoint
- Auto-scaling based on traffic
- ~2 second cold start, <200ms warm inference

---

## Dataset & Vector Database

### Data Curation Process

We built a comprehensive product dataset through multi-stage curation:

#### **1. Data Collection**
- **Source:** [Amazon product listings](https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023)
- **Scraping:** Ethical web scraping with rate limiting
- **Volume:** 1M products across all categories
- **Fields:** Title, description, category, price, rating, reviews, images, URLs

#### **2. Data Cleaning**
```python
# Cleaning pipeline
1. Remove duplicates (by product ID)
2. Filter invalid prices (< $1 or > $10,000)
3. Remove products with missing descriptions
4. Standardize category names
5. Clean HTML from descriptions
6. Remove special characters
7. Validate URLs
```

#### **3. Data Preprocessing**
- Combine title + description into `summary` field
- Normalize prices (remove currency symbols)
- Category mapping (consolidate similar categories)
- Text preprocessing (lowercase, remove extra spaces)

#### **4. Quality Assurance**
- Manual review of sample products
- Statistical outlier detection
- Category distribution validation
- Price range verification

**Final Dataset Statistics:**

| Metric | Value |
|--------|-------|
| Total Products | 800,000 |
| Categories | 30+ |
| Avg Description Length | 150 words |
| Price Range | $1 - $10,000 |
| Median Price | $49.99 |

### 800K Amazon Products

**Category Distribution:**

- Electronics (35%)
- Home & Kitchen (20%)
- Clothing & Accessories (15%)
- Books & Media (10%)
- Sports & Outdoors (8%)
- Beauty & Personal Care (7%)
- Other (5%)

**Dataset Split:**

| Split | Size | Purpose |
|-------|------|---------|
| Training | 800K | Fine-tuning, embeddings |
| Validation | 10K | Model evaluation |
| Test | 10K | Final benchmarking |

**Published on Hugging Face:**
- `Inoussa-guru/items_full` (800K products)
- `Inoussa-guru/items_lite` (200K products)
- Easy loading: `Item.from_hub("Inoussa-guru/items_full")`

### Vector Database Setup

**ChromaDB Configuration:**

```python
# Initialize client
client = chromadb.PersistentClient(path="products_vectorstore")
collection = client.get_or_create_collection("products")

# Embedding model
encoder = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2') # free to use

# Process in batches
for batch in tqdm(data, batch_size=1000):
    documents = [item.summary for item in batch]
    vectors = encoder.encode(documents)  # 384-dim
    metadatas = [{"price": item.price, "category": item.category}]
    collection.add(documents, vectors, metadatas, ids)
```

**Vector Database Details:**

| Specification | Value |
|---------------|-------|
| Vector Dimension | 384 |
| Total Vectors | 800,000 |
| Storage Size | ~2.5 GB |
| Embedding Model | all-MiniLM-L6-v2 |
| Distance Metric | Cosine similarity |
| Index Type | HNSW |

## Getting Started

### Prerequisites

**System Requirements:**
- Python 3.13 or higher
- 8GB RAM minimum (16GB recommended)
- 5GB disk space for vector database
- GPU optional (speeds up processing)

**Supported Platforms:**
- macOS (M1/M2/M3 with MPS support)
- Linux (with CUDA support)
- Windows (CPU-only)

### Installation

**1. Clone the repository:**
```bash
git clone https://github.com/imouiche/LLama3.2-fine-tuned-vs-NNs-LangGraph.git
cd LLama3.2-fine-tuned-vs-NNs-LangGraph
```

**2. Create virtual environment:**
```bash
# Using venv
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Or using conda
conda create -n deals python=3.13
conda activate deals
```

**3. Install dependencies:**
```bash
# Using pip
pip install -r requirements.txt

# Or using uv (faster)
uv pip install -r requirements.txt
```

**Key Dependencies:**
- `langgraph>=0.2.0` - Workflow orchestration
- `openai>=1.0.0` - GPT models
- `torch>=2.0.0` - Neural network
- `chromadb>=0.4.0` - Vector database
- `gradio>=4.0.0` - UI
- `sentence-transformers` - Embeddings
- `modal` - Cloud deployment
- `litellm` - Multi-provider LLM access

### Environment Setup

**1. Create `.env` file:**
```bash
cp .env.example .env
```

**2. Add your API keys:**
```bash
# Required
OPENAI_API_KEY=sk-...                    # OpenAI API
PUSHOVER_USER=your_pushover_user         # Pushover user key
PUSHOVER_TOKEN=your_pushover_token       # Pushover app token

# Required for database population
HF_TOKEN=hf_...                          # Hugging Face token

# Optional (for specialist agent)
MODAL_TOKEN_ID=your_modal_token          # Modal Cloud
MODAL_TOKEN_SECRET=your_modal_secret
```

**Get API Keys:**
- **OpenAI:** https://platform.openai.com/api-keys
- **Pushover:** https://pushover.net/
- **Hugging Face:** https://huggingface.co/settings/tokens
- **Modal:** https://modal.com/

### Database Population

**Option 1: Full dataset (800K products) - Recommended**
```bash
python tools/populate_vectordb.py
```
- Time: ~30-40 minutes on GPU
- Storage: ~2.5GB

**Option 2: Lite dataset (200K products) - For testing**
```bash
python tools/populate_vectordb.py --lite
```
- Time: ~10-15 minutes on GPU
- Storage: ~600MB

**What happens:**
1. Downloads dataset from Hugging Face
2. Encodes products to 384-dim vectors
3. Stores in ChromaDB
4. Creates searchable index

## Usage

### Gradio UI (Recommended)

**Start the UI:**
```bash
python price_is_right.py
```

**Access at:** http://127.0.0.1:7860

### Command Line

**Single run:**
```bash
python deal_agent_framework.py
```

**Output:**
```
[Agent Framework] Initializing...
[Scanner Agent] Found 9 deals, selected 5
[Preprocessing] Cleaned 5 descriptions
[Ensemble Coordinator] Processing deal 1/5
[Frontier/Specialist/NN] Predicting... (parallel)
[Ensemble Aggregator] Estimated $354, Actual $205, Discount $149
...
[Decision] Best discount: $149 > $50 threshold
[Messaging] Notification sent!
‚úÖ Workflow completed successfully
```

**Schedule with cron:**
```bash
# Run every hour
0 * * * * cd /path/to/project && python deal_agent_framework.py
```

### Programmatic Access

**Use as a library:**

```python
from deal_agent_framework import DealAgentFramework

# Initialize
framework = DealAgentFramework()

# Run workflow
opportunities = framework.run()

# Check results
for opp in opportunities:
    print(f"Product: {opp.deal.product_description}")
    print(f"Discount: ${opp.discount:.2f}")
    print(f"URL: {opp.deal.url}")
```

**Advanced usage:**

```python
# Access individual agents
from agents.frontier_agent import FrontierAgent

agent = FrontierAgent(collection=chroma_collection)
price = agent.price("Sony wireless headphones")
print(f"Predicted: ${price:.2f}")

# Use LangGraph workflow directly
from workflows.deal_workflow import build_deal_workflow

workflow = build_deal_workflow()
result = workflow.invoke({
    "chroma_collection": collection,
    "memory": []
})
```
---

## Gradio UI Features

<p align="center">
  <img src="assets/gradio_ui.png" alt="Gradio User Interface" width="100%"/>
</p>

### Real-time Logs

**Color-coded by agent:**
- üü† **Orange** - Agent Framework
- üîµ **Blue** - Scanner Agent
- üü£ **Purple** - Preprocessing
- üü¢ **Green** - Coordinator
- üî¥ **Red** - Predictors (Frontier/Specialist/NN)
- üü† **Orange** - Ensemble
- üü° **Yellow** - Decision
- üîµ **Cyan** - Messaging

**Features:**
- Shows last 18 log messages
- Auto-scrolls to latest
- Updates in real-time
- Timestamps included

### 3D Vector Space Visualization

**What it shows:**
- 800 random products from ChromaDB
- Reduced to 3D using t-SNE
- Colored by product category

**Interactive:**
- Rotate by dragging
- Zoom in/out
- Hover for details

**Purpose:**
- Visualize embedding space
- See product clustering
- Understand RAG retrieval

### Opportunities Table

**Columns:**
1. **Product Description** - What's on sale
2. **Price** - Actual price
3. **Estimate** - Our prediction
4. **Discount** - Savings amount
5. **URL** - Link to product

**Features:**
- Click any row to re-send notification
- Sorted by discount (highest first)
- Updates after each run
- Persisted in `memory.json`

### Auto-refresh

**Configuration:**
```python
timer = gr.Timer(value=300, active=True)  # 300 seconds = 5 minutes
```

**Change interval:**
- Every 1 minute: `value=60`
- Every 10 minutes: `value=600`
- Every hour: `value=3600`

**Disable auto-refresh:**
```python
timer = gr.Timer(value=300, active=False)
```

---

## Performance Metrics

### Execution Time

**Breakdown for 5 deals:**

| Stage | Time | Notes |
|-------|------|-------|
| Scanner | 20-25s | RSS + OpenAI selection |
| Preprocessing | 1-2s | LiteLLM batch processing |
| Per deal prediction | 2-4s | All 3 models in parallel |
| Decision | <1s | Finding best deal |
| Messaging | 1-2s | LLM + Pushover |
| **Total** | **60-90s** | 2x faster than sequential |

### Accuracy Metrics

**Ensemble Performance:**

| Metric | Value | Interpretation |
|--------|-------|----------------|
| MSE | 29.7 | Mean squared error |
| R¬≤ Score | 0.93 | Excellent fit |
| MAE | $42.50 | Mean absolute error |
| Within 20% | 85% | Predictions within 20% of actual |

**Individual Model Performance:**

| Model | MSE | R¬≤ | Speed |
|-------|-----|----|----|
| Frontier (RAG) | 30.1 | 0.92 | ~2.5s |
| Specialist (Fine-tuned) | 46.8 | 0.87 | ~2.0s |
| Neural Network | 64.2 | 0.82 | ~0.2s |
| **Ensemble** | **29.7** | **0.93** | **~2.5s** |

**Speedup: 2.1x faster!** ‚ö°

### Resource Usage

**Memory:**
- ChromaDB: ~2.5GB (disk)
- PyTorch model: ~500MB (RAM)
- Runtime: ~1-2GB (RAM)
- Total: ~4GB peak usage

**CPU/GPU:**
- Apple Silicon (MPS): ~30% utilization
- CUDA GPU: ~40% utilization
- CPU fallback: ~80% utilization

**Network:**
- OpenAI API: ~5-10 requests per run
- Modal Cloud: ~5 requests per run
- RSS feed: ~1 request per run
- Pushover: 1 request if notifying

---

## Project Structure

```
online-product-deals/
‚îú‚îÄ‚îÄ agents/                          # All agent implementations
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ frontier_agent.py           # RAG with ChromaDB
‚îÇ   ‚îú‚îÄ‚îÄ specialist_agent.py         # Fine-tuned Llama on Modal
‚îÇ   ‚îú‚îÄ‚îÄ neural_network_agent.py     # PyTorch deep learning
‚îÇ   ‚îú‚îÄ‚îÄ ensemble_agent.py           # Weighted average
‚îÇ   ‚îú‚îÄ‚îÄ scanner_agent.py            # RSS + OpenAI selection
‚îÇ   ‚îú‚îÄ‚îÄ messaging_agent.py          # Pushover notifications
‚îÇ   ‚îî‚îÄ‚îÄ planning_agent.py           # Legacy (replaced by LangGraph)
‚îÇ
‚îú‚îÄ‚îÄ workflows/                       # LangGraph orchestration
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ state.py                    # State schema (TypedDict)
‚îÇ   ‚îú‚îÄ‚îÄ nodes.py                    # 9 node functions
‚îÇ   ‚îî‚îÄ‚îÄ deal_workflow.py            # Graph builder
‚îÇ
‚îú‚îÄ‚îÄ tools/                          # Utilities and tools
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ deals.py                    # Data models (Deal, Opportunity)
‚îÇ   ‚îú‚îÄ‚îÄ agent_colors.py             # Logging colors
‚îÇ   ‚îú‚îÄ‚îÄ preprocessor.py             # Text cleaning
‚îÇ   ‚îú‚îÄ‚îÄ deep_neural_network.py      # PyTorch model
‚îÇ   ‚îú‚îÄ‚îÄ populate_vectordb.py        # Database population
‚îÇ   ‚îî‚îÄ‚îÄ item.py                     # Dataset loader
‚îÇ
‚îú‚îÄ‚îÄ models/                         # Trained model weights
‚îÇ   ‚îî‚îÄ‚îÄ deep_neural_network.pth     # ~500MB PyTorch model
‚îÇ
‚îú‚îÄ‚îÄ products_vectorstore/           # ChromaDB storage
‚îÇ   ‚îú‚îÄ‚îÄ chroma.sqlite3              # Vector database
‚îÇ   ‚îî‚îÄ‚îÄ [UUID directories]          # Vector data
‚îÇ
‚îú‚îÄ‚îÄ assets/                         # Images and media
‚îÇ   ‚îú‚îÄ‚îÄ langgraph_horizontal.png    # Architecture diagram
‚îÇ   ‚îú‚îÄ‚îÄ gradio_ui.png               # UI screenshot
‚îÇ   ‚îî‚îÄ‚îÄ nn_vs_llm.png               # Model comparison
‚îÇ
‚îú‚îÄ‚îÄ deal_agent_framework.py         # Main entry point
‚îú‚îÄ‚îÄ price_is_right.py               # Gradio UI
‚îú‚îÄ‚îÄ log_utils.py                    # Log formatting
‚îú‚îÄ‚îÄ memory.json                     # Notification history
‚îú‚îÄ‚îÄ requirements.txt                # Python dependencies
‚îú‚îÄ‚îÄ .env.example                    # Environment template
‚îú‚îÄ‚îÄ .gitignore                      # Git ignore rules
‚îú‚îÄ‚îÄ README.md                       # This file
‚îî‚îÄ‚îÄ LICENSE                         # MIT license
```

---

### Sample RSS Feed Sources

**Edit:** `agents/scanner_agent.py`

```python
# Current source
RSS_URL = "https://www.dealnews.com/rss/all-deals/"

# Add multiple sources
RSS_URLS = [
    "https://www.dealnews.com/rss/all-deals/",
    "https://slickdeals.net/newsearch.php?mode=frontpage&rss=1",
    # Add more...
]
```
---

## Demo

<p align="center">
  <a href="https://youtu.be/eEZ3r89180U">
    <img src="assets/gradio_ui.png" alt="Execution Demo" width="80%"/>
  </a>
</p>

<p align="center">
  <i>Click to watch: Complete workflow demonstration with Gradio UI</i>
</p>

**What the demo shows:**
- ‚úÖ Starting the Gradio UI
- ‚úÖ Auto-discovery workflow execution
- ‚úÖ Real-time logs with color coding
- ‚úÖ 3D vector space visualization
- ‚úÖ Parallel prediction execution
- ‚úÖ Deal notification process
- ‚úÖ Table updates with opportunities

---

## Contributing

We welcome contributions! Here's how to get started:

### Quick Start

1. **Fork the repository**
2. **Create a feature branch**
   ```bash
   git checkout -b feature/new-feature
   ```
3. **Make your changes**
4. **Run tests**
   ```bash
   pytest tests/ -v
   ```
5. **Commit with clear message**
   ```bash
   git commit -m "Add new feature"
   ```
6. **Push to your fork**
   ```bash
   git push origin feature/new-feature
   ```
7. **Open a Pull Request**

### Contribution Ideas

**New Features:**
- [ ] Additional data sources (Slickdeals, Amazon Deals, etc.)
- [ ] More AI models in ensemble
- [ ] Email notifications
- [ ] Price history tracking
- [ ] Deal categories/filtering
- [ ] User preferences
- [ ] Mobile app

**Improvements:**
- [ ] Better error handling
- [ ] More comprehensive tests
- [ ] Performance optimizations
- [ ] Documentation improvements
- [ ] UI/UX enhancements

**Bug Fixes:**
- Report bugs via GitHub Issues
- Include error logs and steps to reproduce
- Suggest possible fixes if you have ideas

### Code Style

- Follow PEP 8
- Use type hints
- Add docstrings to functions
- Keep functions focused (single responsibility)
- Write tests for new features

### Testing Guidelines

```bash
# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=agents --cov=workflows --cov-report=html

# Run specific test file
pytest tests/test_new_feature.py -v

# Run tests matching pattern
pytest tests/ -k "test_frontier" -v
```

---

## License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

### Technologies

- **[LangGraph](https://github.com/langchain-ai/langgraph)** - Workflow orchestration framework
- **[OpenAI](https://openai.com/)** - GPT-4o for RAG predictions
- **[Modal](https://modal.com/)** - Serverless deployment platform
- **[Groq](https://groq.com/)** - Fast LLM inference
- **[Meta AI](https://ai.meta.com/)** - Llama 3.2 base model
- **[ChromaDB](https://www.trychroma.com/)** - Vector database
- **[Gradio](https://www.gradio.app/)** - Beautiful UI framework
- **[PyTorch](https://pytorch.org/)** - Deep learning framework
- **[Hugging Face](https://huggingface.co/)** - Model hub and datasets
- **[Weights & Biases](https://wandb.ai/)** - Training monitoring
- **[Sentence Transformers](https://www.sbert.net/)** - Text embeddings

### Inspiration

- RAG papers and implementations
- Ensemble learning research
- LangGraph examples and documentation
- Open-source ML community

### Special Thanks

- Ed donner for teaching me AI&LLM Engineering courses on Udemy
---

## üìß Contact

**Project Maintainer:** Inoussa Mouiche

- üìß Email: mouiche@uwindsor.ca
- üíº LinkedIn: [LinkedIn](https://www.linkedin.com/in/inoussa-mouiche-ph-d-b5b5138b/)
- üêô GitHub: [@imouiche](https://github.com/imouiche?tab=repositories)
- üê¶ Google Scholar: [profile](https://scholar.google.com/citations?user=_d4cEVoAAAAJ&hl=en)
- Hugging Face: [huggingface.co/Inoussa-guru](https://huggingface.co/Inoussa-guru)
**Project Links:**
- üí¨ Discussions: [GitHub Discussions](https://github.com/imouiche/LLama3.2-fine-tuned-vs-NNs-LangGraph.git)

---

<p align="center">
  <b>‚≠ê Star this repo if you find it useful!</b>
</p>

<p align="center">
  <b>Watch for updates and new features!</b>
</p>

<p align="center">
  Made with ‚ù§Ô∏è and passion for AI 
</p>